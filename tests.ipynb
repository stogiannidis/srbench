{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 4/4 [00:00<00:00, 108.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch indices 0 to 16 with 16 messages\n",
      "[{'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D14C20>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D17890>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D164E0>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D17500>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D17080>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D16960>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D158B0>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D16510>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D17AD0>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D15EB0>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D16630>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D172F0>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D174A0>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D155E0>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D143E0>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D17530>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}]\n",
      "Processing batch indices 16 to 32 with 16 messages\n",
      "[{'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D162D0>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D15A60>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D16000>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D15640>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D17D70>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D179E0>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D14890>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D17A40>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D178C0>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D17860>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D16720>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D14680>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D17320>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D15700>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D168D0>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D17650>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}]\n",
      "Processing batch indices 32 to 48 with 16 messages\n",
      "[{'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D15370>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D16E40>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=173x142 at 0x7F3161D17FE0>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=220x197 at 0x7F3161D16180>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=220x197 at 0x7F3161D147A0>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=220x197 at 0x7F3161D17950>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=220x197 at 0x7F3161D17D40>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=220x197 at 0x7F3161D17C80>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=220x197 at 0x7F3161D17B60>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=220x197 at 0x7F3161D14410>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=220x197 at 0x7F3161D14F80>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=220x197 at 0x7F3161D15B80>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=220x197 at 0x7F3161D151C0>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=220x197 at 0x7F3161D155B0>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=220x197 at 0x7F3161D16AE0>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=220x197 at 0x7F3161D15490>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}]\n",
      "Processing batch indices 48 to 55 with 7 messages\n",
      "[{'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=220x197 at 0x7F3161D172C0>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=220x197 at 0x7F3161D15700>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=220x197 at 0x7F3161D168D0>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=220x197 at 0x7F3161D15970>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=220x197 at 0x7F3161D14EC0>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=220x197 at 0x7F3161D16060>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=220x197 at 0x7F3161D14110>}, {'type': 'text', 'text': 'How man candidates are there in the image?\\n'}]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import tqdm\n",
    "\n",
    "data = load_dataset(\"stogian/mrt_fp\", split=\"train\")\n",
    "\n",
    "batch_size = 16\n",
    "results = []\n",
    "\n",
    "# Loop through each sample in the dataset.\n",
    "for i in tqdm.tqdm(range(0, len(data), batch_size), desc=\"Processing batches\", unit=\"batch\"):\n",
    "\tbatch = data[i:i+batch_size]\n",
    "\tmessages = []\n",
    "\tfor j in range(len(batch[\"question\"])):\n",
    "\t\tsample = {key: batch[key][j] for key in batch}\n",
    "\t\tmessages.append({\n",
    "\t\t\t\"role\": \"user\",\n",
    "\t\t\t\"content\": [\n",
    "\t\t\t\t{\"type\": \"image\", \"image\": sample[\"image\"]},\n",
    "\t\t\t\t{\"type\": \"text\", \"text\": sample[\"question\"]},\n",
    "\t\t\t],\n",
    "\t\t})\n",
    "\tprint(f\"Processing batch indices {i} to {min(i+batch_size, len(data))} with {len(messages)} messages\")\n",
    "\tprint(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>pred_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A. Option A is simply the original shape in a ...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A. . . . . . . . . . . . . . . . . . . . . . ....</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. Option A is simply the original shape in a ...</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C. . . . . . . . . . . . . . . . . . . . . . ....</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A. . . . . . . . . . . . . . . . . . . . . . ....</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>A. . . . . . . . . . . . . . . . . . . . . . ....</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A. . . . . . . . . . . . . . . . . . . . . . ....</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>A. . . . . A. . . . . . . . . . . . . . . . . ...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>C. . . . . . . . . . . . . . . . . . . . . . ....</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>A. Option A is simply the original shape in a ...</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           prediction ground_truth pred_y\n",
       "0   A. Option A is simply the original shape in a ...            A      A\n",
       "1   A. . . . . . . . . . . . . . . . . . . . . . ....            C      A\n",
       "2   A. Option A is simply the original shape in a ...            B      A\n",
       "3   C. . . . . . . . . . . . . . . . . . . . . . ....            D      C\n",
       "4   A. . . . . . . . . . . . . . . . . . . . . . ....            C      A\n",
       "..                                                ...          ...    ...\n",
       "95  A. . . . . . . . . . . . . . . . . . . . . . ....            B      A\n",
       "96  A. . . . . . . . . . . . . . . . . . . . . . ....            D      A\n",
       "97  A. . . . . A. . . . . . . . . . . . . . . . . ...            A      A\n",
       "98  C. . . . . . . . . . . . . . . . . . . . . . ....            A      C\n",
       "99  A. Option A is simply the original shape in a ...            C      A\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "res = pd.read_csv('results_llama_full.csv')\n",
    "\n",
    "def preprocess(example):\n",
    "\texample['pred_y'] = example['prediction'].split('.')[0]\n",
    "\treturn example\n",
    "\n",
    "res = res.apply(preprocess, axis=1)\n",
    "res\n",
    "\n",
    "\n",
    "# print(\n",
    "#     f\"Correct {res['pred_y'].eq(res['ground_truth']).sum()} out of {len(res)} | {res['pred_y'].eq(res['ground_truth']).sum() / len(res) * 100:.2f}%\"\n",
    "# )\n",
    "\n",
    "# # # Count A in \"prediction\" and \"answer\"\n",
    "# print(f\"Count A in prediction: {res['pred_y'].eq('B').sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. A\\n2. B\\n3. A\\n4. B\\n5. A\\n6. A\\n7. A\\n8. A\\n9. A\\n10. A\\n11. A\\n12. A\\n13. A\\n14. A\\n15. A\\n16. A\\n17. A\\n18. A\\n19. A\\n20. A\\n21. A\\n22. A\\n23. A\\n24. A\\n25. A\\n26. A\\n27. A\\n2'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relations[\"prediction\"][985]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output/imagesfiveshotv3/metadata.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display, HTML\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbase64\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput/imagesfiveshotv3/metadata.jsonl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      9\u001b[0m \tmetadata \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m     10\u001b[0m metadata \u001b[38;5;241m=\u001b[39m [json\u001b[38;5;241m.\u001b[39mloads(x\u001b[38;5;241m.\u001b[39mstrip()) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m metadata]\n",
      "File \u001b[0;32m/remote/rds/users/s2750560/miniconda3/envs/srbench/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output/imagesfiveshotv3/metadata.jsonl'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "from IPython.display import display, HTML\n",
    "import base64\n",
    "\n",
    "with open(\"output/imagesfiveshotv3/metadata.jsonl\") as f:\n",
    "\tmetadata = f.readlines()\n",
    "metadata = [json.loads(x.strip()) for x in metadata]\n",
    "df = pd.DataFrame(metadata)\n",
    "# Function to encode image to base64\n",
    "def image_to_base64(image_path, width=100):\n",
    "\twith open(image_path, \"rb\") as f:\n",
    "\t\timg_data = f.read()\n",
    "\timg_base64 = base64.b64encode(img_data).decode(\"utf-8\")\n",
    "\treturn f'<img src=\"data:image/jpeg;base64,{img_base64}\" width=\"{width}\"/>'\n",
    "# Apply to DataFrame\n",
    "df[\"image\"] = df[\"image_path\"].apply(image_to_base64)\n",
    "# Save to HTML\n",
    "# df.to_html(\"dataframe_with_images.html\", escape=False)\n",
    "# Display in Jupyter Notebook (optional)\n",
    "display(HTML(df.to_html(escape=False)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt_model', 'prompt', 'task_type', 'diffusion_model', 'image_path', 'generation_details'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read jsonl file and display it in csv format through pandas\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "import sys\n",
    "import ast\n",
    "import os\n",
    "from PIL import Image as PILImage\n",
    "from datasets import Dataset, Features, Value, Image\n",
    "\n",
    "file = \"llm_scene_description_with_image.jsonl\"\n",
    "\n",
    "def read_jsonl(file):\n",
    "\twith open(file, 'r') as f:\n",
    "\t\tdata = f.readlines()\n",
    "\treturn data\n",
    "\n",
    "def jsonl_to_csv(data):\n",
    "\twith open('llm_scene_description_with_image.csv', 'w', newline='') as f:\n",
    "\t\twriter = csv.writer(f)\n",
    "\t\theader_written = False\n",
    "\t\tfor line in data:\n",
    "\t\t\titem = json.loads(line)\n",
    "\t\t\tif not header_written:\n",
    "\t\t\t\twriter.writerow(item.keys())\n",
    "\t\t\t\theader_written = True\n",
    "\t\t\twriter.writerow(item.values())\n",
    "   \n",
    "data = read_jsonl(file)\n",
    "jsonl_to_csv(data)\n",
    "df = pd.read_csv('llm_scene_description_with_image.csv')\n",
    "\n",
    "\n",
    "def process_gen_details(x):\n",
    "\ttry:\n",
    "\t\t# Convert string representation of dict to actual dict\n",
    "\t\td = ast.literal_eval(x)\n",
    "\t\t# Convert dict to a plain text string representation\n",
    "\t\treturn \", \".join([f\"{k}: {v}\" for k, v in d.items()])\n",
    "\texcept Exception as e:\n",
    "\t\treturn x\n",
    "\n",
    "df['generation_details'] = df['generation_details'].apply(process_gen_details)\n",
    "\n",
    "# Improved helper function to load an image and convert it to RGB\n",
    "\n",
    "def load_image(path):\n",
    "\tif not os.path.exists(path):\n",
    "\t\tprint(f\"File not found: {path}\")\n",
    "\t\treturn None\n",
    "\ttry:\n",
    "\t\twith PILImage.open(path) as img:\n",
    "\t\t\treturn img.convert(\"RGB\")\n",
    "\texcept Exception as error:\n",
    "\t\tprint(f\"Error loading {path}: {error}\")\n",
    "\t\treturn None\n",
    "\n",
    "\n",
    "# Create a Hugging Face Dataset from the edited dataframe, letting the Image feature load images from the file paths\n",
    "dataset = Dataset.from_pandas(\n",
    "\tdf,\n",
    "\tfeatures=Features(\n",
    "\t\t{\n",
    "\t\t\t\"prompt_model\": Value(\"string\"),\n",
    "\t\t\t\"prompt\": Value(\"string\"),\n",
    "\t\t\t\"task_type\": Value(\"string\"),\n",
    "\t\t\t\"diffusion_model\": Value(\"string\"),\n",
    "\t\t\t\"image_path\": Image(),  # Use the image_path column as the image feature\n",
    "\t\t\t\"generation_details\": Value(\"string\"),\n",
    "\t\t}\n",
    "\t),\n",
    ")\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "256d6be45e2d4199ae30a46f29bb0f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f576e91e37b34ace95f6c23359313d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08ccc4151bc241dca6b6c6bf2da77d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/stogian/test_dataset/commit/a803433d97210f446a53af892d7fb86760447005', commit_message='Upload dataset', commit_description='', oid='a803433d97210f446a53af892d7fb86760447005', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/stogian/test_dataset', endpoint='https://huggingface.co', repo_type='dataset', repo_id='stogian/test_dataset'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset.push_to_hub(\"test_dataset\", private=True)  # Replace 'your-username' with your actual Hugging Face username."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2211 annotations\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, Image, Features, Value\n",
    "import json\n",
    "from PIL import Image as PILImage\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "def generate_examples():\n",
    "\tfor data in annotations:\n",
    "\t\timage_path = os.path.join(\"Spatial-MM/data\", data[\"image_name\"])\n",
    "\t\ttry:\n",
    "\t\t\timage = PILImage.open(image_path).convert(\"RGB\")  # Load image as RGB\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(\"Error loading image: \", image_path)\n",
    "\t\t\tcontinue\n",
    "\t\tyield {\n",
    "\t\t\t\"image\": image,\n",
    "\t\t\t\"question\": data[\"question\"],\n",
    "\t\t\t\"answer\": data[\"answer\"],\n",
    "\t\t}\n",
    "\n",
    "\n",
    "\t# Load JSON annotations from multiple files\n",
    "annotations = []\n",
    "json_files = glob.glob(\"Spatial-MM/data/Spatial_MM_CoT/*.json\")\n",
    "for json_file in json_files:\n",
    "\twith open(json_file, \"r\") as f:\n",
    "\t\tannotations.extend(json.load(f))\n",
    "\n",
    "print(f\"Loaded {len(annotations)} annotations\")\n",
    "\n",
    "# Define dataset features (adjust based on your JSON structure)\n",
    "# features = Features(\n",
    "# \t{\n",
    "# \t\t\"image\": Image(),\n",
    "# \t\t\"question\": Value(\"string\"),\n",
    "# \t\t\"answer\": Value(\"string\"),\n",
    "# \t}\n",
    "# )\n",
    "\n",
    "# # Create the dataset\n",
    "# dataset = Dataset.from_generator(\n",
    "# \tgenerate_examples,\n",
    "# \tfeatures=features,\n",
    "# )\n",
    "\n",
    "# dataset\n",
    "\t# dataset.push_to_hub(\"spatial_mm\", private=True)  # Push to the Hub\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "source_dirs = ['Spatial-MM/data/Spatial_MM_Obj', 'Spatial-MM/data/Spatial_MM_CoT']\n",
    "target_dir = 'Spatial-MM/data/images'\n",
    "\n",
    "# Create target directory if it doesn't exist\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "for source in source_dirs:\n",
    "\tfor filename in os.listdir(source):\n",
    "\t\tsource_file = os.path.join(source, filename)\n",
    "\t\tif os.path.isfile(source_file):\n",
    "\t\t\tshutil.move(source_file, target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_extensions = [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\"]\n",
    "\n",
    "source_dirs = [\"Spatial-MM/data/Spatial_MM_Obj\", \"Spatial-MM/data/Spatial_MM_CoT\"]\n",
    "target_dir = \"Spatial-MM/data/image_dir\"\n",
    "\n",
    "# Create target directory if it doesn't exist\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "for source in source_dirs:\n",
    "\tfor filename in os.listdir(source):\n",
    "\t\tif os.path.splitext(filename)[1].lower() in image_extensions:\n",
    "\t\t\tshutil.move(os.path.join(source, filename), target_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 5702\n"
     ]
    }
   ],
   "source": [
    "image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif']\n",
    "image_files = [\n",
    "\tf for f in os.listdir('Spatial-MM/data/Spatial_MM_Obj')\n",
    "\tif os.path.splitext(f)[1].lower() in image_extensions\n",
    "]\n",
    "print(f\"Number of images: {len(image_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 33460 annotations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'question', 'answer'],\n",
       "    num_rows: 33460\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, Image, Features, Value\n",
    "import json\n",
    "from PIL import Image as PILImage\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "def generate_examples():\n",
    "\tfor data in annotations:\n",
    "\t\timage_path = os.path.join(\"data/egobrientbench\", data[\"image\"])\n",
    "\t\ttry:\n",
    "\t\t\timage = PILImage.open(image_path).convert(\"RGB\")  # Load image as RGB\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(\"Error loading image: \", image_path)\n",
    "\t\t\tcontinue\n",
    "\t\tyield {\n",
    "\t\t\t\"image\": image,\n",
    "\t\t\t\"question\": data[\"question\"],\n",
    "\t\t\t\"answer\": data[\"label\"],\n",
    "\t\t}\n",
    "\n",
    "\t# Load JSON annotations from multiple files\n",
    "\n",
    "\n",
    "annotations = []\n",
    "json_files = glob.glob(\"data/egobrientbench/benchmark.json\")\n",
    "for json_file in json_files:\n",
    "\twith open(json_file, \"r\") as f:\n",
    "\t\tannotations.extend(json.load(f))\n",
    "\n",
    "print(f\"Loaded {len(annotations)} annotations\")\n",
    "\n",
    "# Define dataset features (adjust based on your JSON structure)\n",
    "features = Features(\n",
    "\t{\n",
    "\t\t\"image\": Image(),\n",
    "\t\t\"question\": Value(\"string\"),\n",
    "\t\t\"answer\": Value(\"string\"),\n",
    "\t}\n",
    ")\n",
    "\n",
    "# Create the dataset\n",
    "dataset = Dataset.from_generator(\n",
    "\tgenerate_examples,\n",
    "\tfeatures=features,\n",
    ")\n",
    "\n",
    "dataset\n",
    "# dataset.push_to_hub(\"spatial_mm\", private=True)  # Push to the Hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16799e0a02e9495cac4d6f7697812dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db37f1b63f4142ff9dce19cf6bc34919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69bd4ef2ef4a41709d81140b1fe838f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/38 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc05ed14059d4dfaa0715ab3453a4881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b74b1fe8f72a409495946aff638ff24c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/38 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71cd24870d174a34b76e2e1330e8b13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04ae79cdd5584f9c91ac9f1791a02c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/38 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf3de3c255b4635a009ede00e256fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81612b80c0f848e2831e49ac6631fbc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/38 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e6d2c8e7604c3d89d7daf67c532ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9662b52fb6794f30ac5d1163699dd80b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/38 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b787fd88ef4ea0bef8092f2e3843d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7afc823c34c4d9e92700ca4b1a3ed45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/38 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a354eece9b2427db7123237614fbbdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "635507d5469b4f60a203b6965cb158b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/38 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78aef6d280f94d60bc0a3d5cc18cab24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3717 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f584fa912242e7885575bb02d749d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/38 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dfd7bde9cd141a4b909c077cf39813b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3717 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b83de68a05a745f38395902597d7f6e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/38 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/stogian/egoorientbench/commit/555bae171477e4755b0193eed2cc9f6c42b4d6e5', commit_message='Upload dataset', commit_description='', oid='555bae171477e4755b0193eed2cc9f6c42b4d6e5', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/stogian/egoorientbench', endpoint='https://huggingface.co', repo_type='dataset', repo_id='stogian/egoorientbench'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.push_to_hub(\"stogian/egoorientbench\", private=True )  # Push to the Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "!pip install transformers\n",
    "\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "model = AutoModel.from_pretrained(model_name, cache_dir=\"../bin/models/\"+model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=\"../bin/models/\"+model_name)\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>correct</th>\n",
       "      <th>raw_prediction</th>\n",
       "      <th>candidate_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>Candidate 4. ### Answer: Candidate 4. ### Expl...</td>\n",
       "      <td>['mirror', 'similar', 'rotate', 'mirror']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>Candidate 2. ### Answer: Candidate 2. ### Expl...</td>\n",
       "      <td>['mirror', 'mirror', 'similar', 'rotate']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>Candidate 1, Candidate 2, Candidate 3, Candida...</td>\n",
       "      <td>['mirror', 'similar', 'mirror', 'rotate']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>Candidate 1, Candidate 2, Candidate 3, Candida...</td>\n",
       "      <td>['mirror', 'mirror', 'rotate', 'similar']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Candidate 4. ### Answer: Candidate 4. ### Expl...</td>\n",
       "      <td>['rotate', 'mirror', 'mirror', 'similar']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>Candidate 1. ### Answer: Candidate 1. ### Expl...</td>\n",
       "      <td>['rotate', 'similar', 'mirror', 'mirror']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Candidate 2. ### Answer: Candidate 2. ### Expl...</td>\n",
       "      <td>['rotate', 'mirror', 'similar', 'mirror']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>Candidate 1. ### Answer: Candidate 1. ### Expl...</td>\n",
       "      <td>['mirror', 'rotate', 'similar', 'mirror']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>Candidate 3.ourgardenstate.com/ourgarden.com/o...</td>\n",
       "      <td>['mirror', 'similar', 'mirror', 'rotate']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>Candidate 1, Candidate 2, Candidate 3, Candida...</td>\n",
       "      <td>['mirror', 'mirror', 'similar', 'rotate']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     prediction  ground_truth  correct  \\\n",
       "0             4             3    False   \n",
       "1             2             4    False   \n",
       "2             1             4    False   \n",
       "3             1             3    False   \n",
       "4             4             1    False   \n",
       "..          ...           ...      ...   \n",
       "495           1             1     True   \n",
       "496           2             1    False   \n",
       "497           1             2    False   \n",
       "498           3             4    False   \n",
       "499           1             4    False   \n",
       "\n",
       "                                        raw_prediction  \\\n",
       "0    Candidate 4. ### Answer: Candidate 4. ### Expl...   \n",
       "1    Candidate 2. ### Answer: Candidate 2. ### Expl...   \n",
       "2    Candidate 1, Candidate 2, Candidate 3, Candida...   \n",
       "3    Candidate 1, Candidate 2, Candidate 3, Candida...   \n",
       "4    Candidate 4. ### Answer: Candidate 4. ### Expl...   \n",
       "..                                                 ...   \n",
       "495  Candidate 1. ### Answer: Candidate 1. ### Expl...   \n",
       "496  Candidate 2. ### Answer: Candidate 2. ### Expl...   \n",
       "497  Candidate 1. ### Answer: Candidate 1. ### Expl...   \n",
       "498  Candidate 3.ourgardenstate.com/ourgarden.com/o...   \n",
       "499  Candidate 1, Candidate 2, Candidate 3, Candida...   \n",
       "\n",
       "                               candidate_order  \n",
       "0    ['mirror', 'similar', 'rotate', 'mirror']  \n",
       "1    ['mirror', 'mirror', 'similar', 'rotate']  \n",
       "2    ['mirror', 'similar', 'mirror', 'rotate']  \n",
       "3    ['mirror', 'mirror', 'rotate', 'similar']  \n",
       "4    ['rotate', 'mirror', 'mirror', 'similar']  \n",
       "..                                         ...  \n",
       "495  ['rotate', 'similar', 'mirror', 'mirror']  \n",
       "496  ['rotate', 'mirror', 'similar', 'mirror']  \n",
       "497  ['mirror', 'rotate', 'similar', 'mirror']  \n",
       "498  ['mirror', 'similar', 'mirror', 'rotate']  \n",
       "499  ['mirror', 'mirror', 'similar', 'rotate']  \n",
       "\n",
       "[500 rows x 5 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.read_csv(\"results.csv\")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.23\n",
      "Precision: 0.22\n",
      "Recall: 0.23\n",
      "F1: 0.19\n",
      "F1: 0.19\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score\n",
    "\n",
    "y_true = results[\"ground_truth\"]\n",
    "y_pred = results[\"prediction\"]\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1: {f1:.2f}\")\n",
    "\n",
    "f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "print(f\"F1: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "srbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
