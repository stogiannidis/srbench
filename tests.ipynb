{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt_model', 'prompt', 'task_type', 'diffusion_model', 'image_path', 'generation_details'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read jsonl file and display it in csv format through pandas\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "import sys\n",
    "import ast\n",
    "import os\n",
    "from PIL import Image as PILImage\n",
    "from datasets import Dataset, Features, Value, Image\n",
    "\n",
    "file = \"llm_scene_description_with_image.jsonl\"\n",
    "\n",
    "def read_jsonl(file):\n",
    "\twith open(file, 'r') as f:\n",
    "\t\tdata = f.readlines()\n",
    "\treturn data\n",
    "\n",
    "def jsonl_to_csv(data):\n",
    "\twith open('llm_scene_description_with_image.csv', 'w', newline='') as f:\n",
    "\t\twriter = csv.writer(f)\n",
    "\t\theader_written = False\n",
    "\t\tfor line in data:\n",
    "\t\t\titem = json.loads(line)\n",
    "\t\t\tif not header_written:\n",
    "\t\t\t\twriter.writerow(item.keys())\n",
    "\t\t\t\theader_written = True\n",
    "\t\t\twriter.writerow(item.values())\n",
    "   \n",
    "data = read_jsonl(file)\n",
    "jsonl_to_csv(data)\n",
    "df = pd.read_csv('llm_scene_description_with_image.csv')\n",
    "\n",
    "\n",
    "def process_gen_details(x):\n",
    "\ttry:\n",
    "\t\t# Convert string representation of dict to actual dict\n",
    "\t\td = ast.literal_eval(x)\n",
    "\t\t# Convert dict to a plain text string representation\n",
    "\t\treturn \", \".join([f\"{k}: {v}\" for k, v in d.items()])\n",
    "\texcept Exception as e:\n",
    "\t\treturn x\n",
    "\n",
    "df['generation_details'] = df['generation_details'].apply(process_gen_details)\n",
    "\n",
    "# Improved helper function to load an image and convert it to RGB\n",
    "\n",
    "def load_image(path):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"File not found: {path}\")\n",
    "        return None\n",
    "    try:\n",
    "        with PILImage.open(path) as img:\n",
    "            return img.convert(\"RGB\")\n",
    "    except Exception as error:\n",
    "        print(f\"Error loading {path}: {error}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Create a Hugging Face Dataset from the edited dataframe, letting the Image feature load images from the file paths\n",
    "dataset = Dataset.from_pandas(\n",
    "    df,\n",
    "    features=Features(\n",
    "        {\n",
    "            \"prompt_model\": Value(\"string\"),\n",
    "            \"prompt\": Value(\"string\"),\n",
    "            \"task_type\": Value(\"string\"),\n",
    "            \"diffusion_model\": Value(\"string\"),\n",
    "            \"image_path\": Image(),  # Use the image_path column as the image feature\n",
    "            \"generation_details\": Value(\"string\"),\n",
    "        }\n",
    "    ),\n",
    ")\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "256d6be45e2d4199ae30a46f29bb0f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f576e91e37b34ace95f6c23359313d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08ccc4151bc241dca6b6c6bf2da77d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/stogian/test_dataset/commit/a803433d97210f446a53af892d7fb86760447005', commit_message='Upload dataset', commit_description='', oid='a803433d97210f446a53af892d7fb86760447005', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/stogian/test_dataset', endpoint='https://huggingface.co', repo_type='dataset', repo_id='stogian/test_dataset'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset.push_to_hub(\"test_dataset\", private=True)  # Replace 'your-username' with your actual Hugging Face username."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2211 annotations\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, Image, Features, Value\n",
    "import json\n",
    "from PIL import Image as PILImage\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "def generate_examples():\n",
    "\tfor data in annotations:\n",
    "\t\timage_path = os.path.join(\"Spatial-MM/data\", data[\"image_name\"])\n",
    "\t\ttry:\n",
    "\t\t\timage = PILImage.open(image_path).convert(\"RGB\")  # Load image as RGB\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(\"Error loading image: \", image_path)\n",
    "\t\t\tcontinue\n",
    "\t\tyield {\n",
    "\t\t\t\"image\": image,\n",
    "\t\t\t\"question\": data[\"question\"],\n",
    "\t\t\t\"answer\": data[\"answer\"],\n",
    "\t\t}\n",
    "\n",
    "\n",
    "\t# Load JSON annotations from multiple files\n",
    "annotations = []\n",
    "json_files = glob.glob(\"Spatial-MM/data/Spatial_MM_CoT/*.json\")\n",
    "for json_file in json_files:\n",
    "\twith open(json_file, \"r\") as f:\n",
    "\t\tannotations.extend(json.load(f))\n",
    "\n",
    "print(f\"Loaded {len(annotations)} annotations\")\n",
    "\n",
    "# Define dataset features (adjust based on your JSON structure)\n",
    "# features = Features(\n",
    "# \t{\n",
    "# \t\t\"image\": Image(),\n",
    "# \t\t\"question\": Value(\"string\"),\n",
    "# \t\t\"answer\": Value(\"string\"),\n",
    "# \t}\n",
    "# )\n",
    "\n",
    "# # Create the dataset\n",
    "# dataset = Dataset.from_generator(\n",
    "# \tgenerate_examples,\n",
    "# \tfeatures=features,\n",
    "# )\n",
    "\n",
    "# dataset\n",
    "\t# dataset.push_to_hub(\"spatial_mm\", private=True)  # Push to the Hub\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "source_dirs = ['Spatial-MM/data/Spatial_MM_Obj', 'Spatial-MM/data/Spatial_MM_CoT']\n",
    "target_dir = 'Spatial-MM/data/images'\n",
    "\n",
    "# Create target directory if it doesn't exist\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "for source in source_dirs:\n",
    "\tfor filename in os.listdir(source):\n",
    "\t\tsource_file = os.path.join(source, filename)\n",
    "\t\tif os.path.isfile(source_file):\n",
    "\t\t\tshutil.move(source_file, target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_extensions = [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\"]\n",
    "\n",
    "source_dirs = [\"Spatial-MM/data/Spatial_MM_Obj\", \"Spatial-MM/data/Spatial_MM_CoT\"]\n",
    "target_dir = \"Spatial-MM/data/image_dir\"\n",
    "\n",
    "# Create target directory if it doesn't exist\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "for source in source_dirs:\n",
    "\tfor filename in os.listdir(source):\n",
    "\t\tif os.path.splitext(filename)[1].lower() in image_extensions:\n",
    "\t\t\tshutil.move(os.path.join(source, filename), target_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 5702\n"
     ]
    }
   ],
   "source": [
    "image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif']\n",
    "image_files = [\n",
    "\tf for f in os.listdir('Spatial-MM/data/Spatial_MM_Obj')\n",
    "\tif os.path.splitext(f)[1].lower() in image_extensions\n",
    "]\n",
    "print(f\"Number of images: {len(image_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 33460 annotations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'question', 'answer'],\n",
       "    num_rows: 33460\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, Image, Features, Value\n",
    "import json\n",
    "from PIL import Image as PILImage\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "def generate_examples():\n",
    "\tfor data in annotations:\n",
    "\t\timage_path = os.path.join(\"data/egobrientbench\", data[\"image\"])\n",
    "\t\ttry:\n",
    "\t\t\timage = PILImage.open(image_path).convert(\"RGB\")  # Load image as RGB\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(\"Error loading image: \", image_path)\n",
    "\t\t\tcontinue\n",
    "\t\tyield {\n",
    "\t\t\t\"image\": image,\n",
    "\t\t\t\"question\": data[\"question\"],\n",
    "\t\t\t\"answer\": data[\"label\"],\n",
    "\t\t}\n",
    "\n",
    "\t# Load JSON annotations from multiple files\n",
    "\n",
    "\n",
    "annotations = []\n",
    "json_files = glob.glob(\"data/egobrientbench/benchmark.json\")\n",
    "for json_file in json_files:\n",
    "\twith open(json_file, \"r\") as f:\n",
    "\t\tannotations.extend(json.load(f))\n",
    "\n",
    "print(f\"Loaded {len(annotations)} annotations\")\n",
    "\n",
    "# Define dataset features (adjust based on your JSON structure)\n",
    "features = Features(\n",
    "\t{\n",
    "\t\t\"image\": Image(),\n",
    "\t\t\"question\": Value(\"string\"),\n",
    "\t\t\"answer\": Value(\"string\"),\n",
    "\t}\n",
    ")\n",
    "\n",
    "# Create the dataset\n",
    "dataset = Dataset.from_generator(\n",
    "\tgenerate_examples,\n",
    "\tfeatures=features,\n",
    ")\n",
    "\n",
    "dataset\n",
    "# dataset.push_to_hub(\"spatial_mm\", private=True)  # Push to the Hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16799e0a02e9495cac4d6f7697812dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db37f1b63f4142ff9dce19cf6bc34919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69bd4ef2ef4a41709d81140b1fe838f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/38 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc05ed14059d4dfaa0715ab3453a4881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b74b1fe8f72a409495946aff638ff24c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/38 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71cd24870d174a34b76e2e1330e8b13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04ae79cdd5584f9c91ac9f1791a02c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/38 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf3de3c255b4635a009ede00e256fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81612b80c0f848e2831e49ac6631fbc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/38 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e6d2c8e7604c3d89d7daf67c532ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9662b52fb6794f30ac5d1163699dd80b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/38 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b787fd88ef4ea0bef8092f2e3843d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7afc823c34c4d9e92700ca4b1a3ed45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/38 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a354eece9b2427db7123237614fbbdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "635507d5469b4f60a203b6965cb158b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/38 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78aef6d280f94d60bc0a3d5cc18cab24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3717 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f584fa912242e7885575bb02d749d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/38 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dfd7bde9cd141a4b909c077cf39813b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3717 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b83de68a05a745f38395902597d7f6e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/38 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/stogian/egoorientbench/commit/555bae171477e4755b0193eed2cc9f6c42b4d6e5', commit_message='Upload dataset', commit_description='', oid='555bae171477e4755b0193eed2cc9f6c42b4d6e5', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/stogian/egoorientbench', endpoint='https://huggingface.co', repo_type='dataset', repo_id='stogian/egoorientbench'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.push_to_hub(\"stogian/egoorientbench\", private=True )  # Push to the Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "!pip install transformers\n",
    "\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "model = AutoModel.from_pretrained(model_name, cache_dir=\"../bin/models/\"+model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=\"../bin/models/\"+model_name)\n",
    "notebook_login()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "srbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
